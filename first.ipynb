{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is an ensemble technique in machine learning?\n",
    "\"\"\"An ensemble technique in machine learning is a method of combining the predictions of multiple individual models to improve \n",
    "the overall predictive power of the system. In an ensemble, several models are trained independently using different algorithms, \n",
    "features, or subsets of the data.\n",
    "\n",
    "There are several types of ensemble techniques, including:\n",
    "\n",
    "Bagging--- Bootstrap aggregating, or bagging, involves training multiple models on different subsets of the training data, with \n",
    "replacement, and combining their predictions.\n",
    "\n",
    "\n",
    "\n",
    "Boosting---- Boosting involves training multiple models sequentially, where each model is trained to improve the performance of \n",
    "the previous one.\n",
    "\n",
    "Stacking: Stacking involves training multiple models and using their outputs as input features for a meta-model that learns \n",
    "to combine them optimally.\n",
    "\n",
    "Ensemble techniques are often used in machine learning to reduce overfitting and increase the accuracy and stability of predictions.\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Why are ensemble techniques used in machine learning?\n",
    "\"\"\"Ensemble techniques are used in machine learning for several reasons, including:\n",
    "\n",
    "\n",
    "\n",
    "Ensemble technique combine the predictions of multiple models which can lead to better accuracy than the individual model .\n",
    "\n",
    "Ensemble technique reduceses overfitting. Individual models may overfit the training data, meaning they perform well on the \n",
    "training data but not on new, unseen data. Ensemble techniques can help to reduce overfitting by combining the predictions of \n",
    "multiple models that havebeen trained using different algorithms, features, or subsets of the data.\n",
    " \n",
    "Ensemble technique can increased stability. Ensemble techniques can improve the stability of predictions by reducing the impact \n",
    "of random variations in the data or in the individual models.\n",
    "\n",
    "Ensemble technique better handles   complex datasets. Ensemble techniques can help to handle complex datasets that have a large\n",
    " number of features or noisy data. By combining the outputs of multiple models, ensemble techniques can capture a more comprehensive representation\n",
    " of the underlying patterns in the data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. What is bagging?\n",
    "\"\"\"Bagging  is an ensemble technique in machine learning that involves building multiple independent models using different subsets \n",
    "of the training data with replacement, and then combining their predictions by averaging or voting.\n",
    "\n",
    "The idea behind bagging is to reduce the variance of individual models by combining the outputs of several models trained on \n",
    "different subsets of the data. The subsets are created by sampling the training data with replacement, which means that some \n",
    "samples may be included in multiple subsets and others may be excluded entirely.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What is boosting?\n",
    "\"\"\"Boosting is an ensemble technique in machine learning that involves building multiple models sequentially, with each model \n",
    "learning to correct the errors of the previous model. The goal of boosting is to improve the accuracy of the ensemble by \n",
    "focusing on the samples that were misclassified by the previous models.\n",
    "\n",
    "In boosting, each model is trained on a weighted version of the training data, where the weights are adjusted to give more \n",
    "importance to the misclassified samples. The output of each model is then combined with the outputs of the previous models \n",
    "using a weighted sum.\n",
    "\n",
    "There are several popular algorithms for boosting, including\n",
    " AdaBoost \n",
    " Gradient Boosting\n",
    " XGBoost. \n",
    " These algorithms differ in their approach to adjusting the weights of the training samples and the construction of the \n",
    " individual models.\n",
    "\n",
    "Boosting can help to improve the accuracy and reduce the bias of machine learning models, especially in cases where \n",
    "the individual models are prone to underfitting or have high bias. Boosting is widely used in applications such as classification \n",
    "and regression, and has been shown to be effective in a wide range of domains.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. What are the benefits of using ensemble techniques?\n",
    "\"\"\"\n",
    "\n",
    "Improved accuracy--- Ensemble techniques can significantly improve the accuracy of machine learning models by combining the \n",
    "predictions of multiple models.\n",
    "\n",
    "Reduced overfitting--- Ensemble techniques can help to reduce the overfitting of individual models by combining the predictions\n",
    " of multiple models that have been trained using different algorithms, features, or subsets of the data.\n",
    "\n",
    "Increased stability--- Ensemble techniques can improve the stability of predictions by reducing the impact of random variations \n",
    "in the data or in the individual models.\n",
    "\n",
    "Better handling of complex datasets--- Ensemble techniques can help to handle complex datasets that have a large number of features\n",
    " or noisy data. By combining the outputs of multiple models, ensemble techniques can capture a more comprehensive representation \n",
    " of the underlying patterns in the data.\n",
    "\n",
    "Flexibility--- Ensemble techniques can be used with a wide range of machine learning models and can be customized to suit specific\n",
    " applications.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Are ensemble techniques always better than individual models?.\n",
    "\"\"\"Ensemble techniques are not always better than individual models. While ensemble techniques can help to improve the accuracy\n",
    " and stability of machine learning models, there are cases where individual models may perform better or where ensemble techniques\n",
    "  may not be effective.\n",
    "\n",
    "if the individual models are already highly accurate and well-calibrated, there may not be much room for improvement \n",
    "with ensemble techniques. Similarly, if the individual models have low bias but high variance, then ensemble techniques may not be\n",
    " as effective in improving the accuracy of the model.\n",
    "\n",
    "ensemble techniques can be computationally expensive and may require more resources than individual models. \n",
    "Therefore, the decision to use ensemble techniques should be based on a careful evaluation of the trade-offs between accuracy,\n",
    " efficiency, and computational resources.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. How is the confidence interval calculated using bootstrap?The confidence interval can be calculated using bootstrap by performing the following steps:\n",
    "\n",
    "\"\"\"Randomly sample the data from the original dataset with replacement to create a new \"bootstrap\" dataset. The new dataset should\n",
    " have the same size as the original dataset.\n",
    "\n",
    "Calculate the  the mean, median, or standard deviation for the bootstrap dataset.\n",
    "\n",
    "Calculate the percentile intervals of the distribution to obtain the confidence interval. For example, to obtain a 95% confidence \n",
    "interval, you would take the 2.5th and 97.5th percentiles of the distribution.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. How does bootstrap work and What are the steps involved in bootstrap?\n",
    "\"\"\"Bootstrap is a resampling technique that is used to estimate the variability of a statistic or to construct a confidence \n",
    "interval for a population parameter. The main idea behind bootstrap is to use the observed data to create multiple \"bootstrap\" \n",
    "samples by resampling the data with replacement.\n",
    "\n",
    "\n",
    "Sample with replacement--- Randomly select a sample of size n from the original dataset, with replacement.\n",
    " \n",
    "\n",
    "Calculate the statistic of interest--- Calculate the desired statistic  mean, median, variance for the bootstrap sample.\n",
    "\n",
    "Repeat steps 1 and 2 a large number of times e.g., 1000 times to create a distribution of the statistic.\n",
    "\n",
    "Calculate the confidence interval---Use the distribution of the statistic to calculate a confidence interval for the population \n",
    "parameter of interest.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for the population mean height: (14.540047212356928, 15.574903931820506)\n"
     ]
    }
   ],
   "source": [
    "# Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a\n",
    "# sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use\n",
    "# bootstrap to estimate the 95% confidence interval for the population mean height.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "sample = np.random.normal(loc=15, scale=2, size=50)\n",
    "n_bootstrap = 1000\n",
    "bootstrap_means = np.zeros(n_bootstrap)\n",
    "for i in range(n_bootstrap):\n",
    "    bootstrap_sample = np.random.choice(sample, size=len(sample), replace=True)\n",
    "    bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "\n",
    "lower_bound = np.percentile(bootstrap_means, 2.5)\n",
    "upper_bound = np.percentile(bootstrap_means, 97.5)\n",
    "confidence_interval = (lower_bound, upper_bound)\n",
    "\n",
    "print(f\"95% confidence interval for the population mean height: {confidence_interval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
